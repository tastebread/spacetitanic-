import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error,r2_score
import matplotlib.pyplot as plt
from category_encoders import OneHotEncoder
from category_encoders import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import plot_confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import RidgeCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import f_regression, SelectKBest
from sklearn.linear_model import Ridge
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import DecisionTreeRegressor
from pandas_profiling import ProfileReport
from category_encoders import TargetEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import validation_curve
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint,uniform
import seaborn as sns
import warnings
warnings.filterwarnings(action='ignore')
train = pd.read_csv('/Users/tastebread/Desktop/kaggle/spacetitanic/train.csv')
test = pd.read_csv('/Users/tastebread/Desktop/kaggle/spacetitanic/test.csv')

train,test = train_test_split(train, test_size=260, random_state=2)
print(train.shape,test.shape)

target = 'Transported'
features = train.columns.drop([target])
X_train = train[features]
y_train = train[target]

X_test = test[features]
y_test = test[target]
#교차 검증 수행
"""
pipe = make_pipeline(
    OneHotEncoder(use_cat_names=True),
    SimpleImputer(strategy='mean'),
    StandardScaler(),
    SelectKBest(f_regression, k=20),
    Ridge(alpha=1.0)

)

#교차 검증 수행
k = 3
scores = cross_val_score(pipe, X_train,y_train,cv=k,
                         scoring='neg_mean_absolute_error')
print(f'MAE ({k} Folds) : ',-scores)
print(f'평균 : {-scores.mean()} 표준편차 : {-scores.std()}')
"""
#랜덤포레스트 적용
"""
pipe = make_pipeline(
    TargetEncoder(min_samples_leaf=1, smoothing=1),
    #TargetEncoder : 범주형 변수 인코더로,타겟값의 특성을 범주별로 평균을 내어 그 값으로 인코딩
    SimpleImputer(strategy='median'),
    RandomForestRegressor(max_depth= 10, n_jobs=-1,random_state=2)
)

k = 3

scores = cross_val_score(pipe, X_train,y_train,cv=k,
                         scoring='neg_mean_absolute_error')
print(f'MAE for {k} folds : ', -scores)
print(f'평균 : {-scores.mean()} 표준편차 : {-scores.std()}')

print(X_train.describe(exclude='number')) #타겟 인코딩 확인

enc = TargetEncoder(min_samples_leaf=1, smoothing=1000)
enc.fit_transform(X_train,y_train)['HomePlanet'].value_counts()

print(X_train['HomePlanet'].value_counts())
"""
#1.하이퍼파라미터 튜닝
"""
사이킷런을 사용해서 하이퍼파라미터를 최적화 할수 있다
머신러닝 모델을 만들때 중요한 것은 최적화,일반화 이다
최적화 : 훈련 데이터로 더 좋은 성능을 얻기 위해 모델을 조정하는 과정
일반화 : 학습된 모델이 처음 본 데이터에서 얼마나 좋은 성능을 내는지 이야기 하는것
모델의 복잡도를 높이는 과정에서 훈련/검증 세트의 손실이 함께 감소하는 시점은 과소적합(underfitting) 되었다고 합니다.
훈련데이터의 손실은 계속 감소하는데 검증데이터의 손실은 증가하는 때가 있습니다. 이때 우리는 과적합(overfitting) 되었다고 합니다
이상적인 모델은 과소적합과 과적합 사이에 존재한다
"""

#1.1검증곡선 그려보기
"""
검증곡선 : 훈련/검증데이터에 대해 y축 : 스코어, x축 : 하이퍼파라미터로 그린 그래프이다
(훈련곡선(learning curve)이라는 용어는 x축이 훈련데이터 수(# of training samples)에 대해 그린 것)
Scikit-learn validation curves 를 사용하면 다양한 하이퍼파라미터 값에 대해 훈련/검증 스코어 값의 변화를 확인할 수 있습니다
"""
"""
pipe = make_pipeline(
    OrdinalEncoder(),
    SimpleImputer(),
    DecisionTreeRegressor()
)

depth = range(1,30,2)
ts,vs = validation_curve(
    pipe, X_train,y_train,
    param_name = 'decisiontreeregressor__max_depth',
    param_range = depth, scoring='neg_mean_absolute_error',
    cv=3,
    n_jobs=-1
)

train_socres_mean = np.mean(-ts, axis=1)
validation_scores_mean = np.mean(-vs,axis=1)


fig,ax = plt.subplots()

#훈련세트 검증곡선
ax.plot(depth, train_socres_mean, label='training error')
#검증세트 검증곡선
ax.plot(depth, validation_scores_mean, label='validation error')
#이상적인 max_depth 의 크기
ax.vlines(4,0, train_socres_mean.max(), color='blue')

#그래프 셋팅
ax.set(title='Validation curve',
       xlabel= 'Model complexity(max_depth)',ylabel='MAE')
ax.legend()
fig.dpi = 100
plt.show()
"""
#결과 : max_depth = 4  부근에서 설정해주면 과적합을 막고 일반화 성능을 지킬 수 있을것같다

#1.2 Randomized Search CV
"""
여러 하이퍼파라미터의 최적값을 찾기 위한 randomizedSearchCV 사용
하이퍼파라미터 : 모델 훈련중에 학습이 되지 않는 파라미터로 사용자가 직접 지정해 주어야한다
현실적으로 일일이 수작업으로 정해주는것은 어렵고 최적의 하이퍼파라미터 조합을 찾아주는 도구를 사용해야한다 (사이킷런에는 두가지 툴이있음)

GridSearchCV : 검증하고 싶은 하이퍼파라미터 수치를 정해주고 그 조합을 모두 검증함
RandomizedSearchCV : 검증하려는 하이퍼파라미터들의 범위를 지정해주면 무작위로 값을 지정해 그 조합을 모두 검증
"""
#1.3 Ridge 회귀모델의 하이퍼 파라미터를 튜닝해보기
"""
pipe = make_pipeline(
    OneHotEncoder(use_cat_names=True),
    SimpleImputer(),
    StandardScaler(),
    SelectKBest(f_regression),
    Ridge()
)

#튜닝할 하이퍼 파라미터 범위를 지정해 주는 부분

disit = {
    'simplteimputer__strategy' : ['mean','median'],
    'selectKBest__k' : range(1, len(X_train.columns)+1),
    'ridge_alpha' : [0.1,1,10],
}

clf = RandomizedSearchCV(
    pipe,
    param_distributions=disit,
    n_iter=50,
    cv=3,
    scoring='neg_mean_absolute_error',
    verbose=1,
    n_jobs=-1
)
clf.fit(X_train,y_train)
print(f'최적 하이퍼파라미터 : {clf.best_params_}')
print(f'MAE : {-clf.best_score_}')
""" #아직 미완성

#1.4 scipy.stats 를 사용해 파라미터 선택을 위한 다양한 분포모듈 사용해보기

pipe = make_pipeline(
    TargetEncoder(),
    SimpleImputer(),
    RandomForestRegressor(random_state=2)
)
dist = {
    'targetencoder__smoothing': [2.,20.,50.,60.,100.,500.,1000.], # int로 넣으면 error(bug)
    'targetencoder__min_samples_leaf': randint(1, 10),
    'simpleimputer__strategy': ['mean', 'median'],
    'randomforestregressor__n_estimators': randint(50, 500),
    'randomforestregressor__max_depth': [5, 10, 15, 20, None],
    'randomforestregressor__max_features': uniform(0, 1) # max_features
}

clf = RandomizedSearchCV(
    pipe,
    param_distributions=dist,
    n_iter=50,
    cv=3,
    scoring='neg_mean_absolute_error',
    verbose=1,
    n_jobs=-1
)

clf.fit(X_train, y_train)
print(f'최적 하이퍼파라미터 : {clf.best_params_}')
print(f'MAE : {-clf.best_score_}')

#각 하이퍼파라미터 조합으로 만들어진 모델들을 순위별로 나열하기
dst = pd.DataFrame(clf.cv_results_).sort_values(by='rank_test_score').T
print(dst)

#테스트 데이터에 대한 예측 결과를 살펴보기

pipe = clf.best_estimator_ #만들어진 모델에서 가장 성능이 좋은 모델 불러오기
"""
best_estimator_ : CV가 끝난 후 찾은 best parameter를 사용해 모든 학습데이터를 가지고 다시 학습한(fit) 상태
"""
y_pred = pipe.predict(X_test)
mae = mean_absolute_error(y_test,y_pred)
print(f'테스트 세트 MAE : {mae}')

#번외 : 선형회귀,랜덤포레스트 모델들의 튜닝 추천 하이퍼파라미터
"""
RandomForst
1.class_weight (뷸균형 클래스 인 경우)
2.max_depth( 너무 깊어지면 과적합)
3.n_estimators(적을경우 과소적합, 높을경우 긴 학습시간)
4.min_samples_leaf( 과적합일경우 높인다)
5.max_features(줄일 수록 다양한 트리 생성

Logistic Regression
1.C (Inverse of regularization strength)
2.class_weight(뷸균형 클래스 인 경우)
3.penalty

Ridge / lasso Regression
1.alpha
"""
